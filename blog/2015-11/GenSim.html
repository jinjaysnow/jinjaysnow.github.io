<!doctype html>
<html lang="zh">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="date" content="2015-11">
<meta name="keywords" content="Gensim,Python,Tf-Idf,LSA,LDA,RP,机器学习,文本处理">
<meta name="description" content="Gensim, Python文档处理库，用于机器学习等数据预处理。">
<meta name="authors" content="Jin Jay"><style>
</style><style>.codehilite pre .hll { background-color: #ffffcc }
.codehilite pre  { background: #f0f3f3; }
.codehilite pre .c { color: #0099FF; font-style: italic } /* Comment */
.codehilite pre .err { color: #AA0000; background-color: #FFAAAA } /* Error */
.codehilite pre .k { color: #006699; font-weight: bold } /* Keyword */
.codehilite pre .o { color: #555555 } /* Operator */
.codehilite pre .ch { color: #0099FF; font-style: italic } /* Comment.Hashbang */
.codehilite pre .cm { color: #0099FF; font-style: italic } /* Comment.Multiline */
.codehilite pre .cp { color: #009999 } /* Comment.Preproc */
.codehilite pre .cpf { color: #0099FF; font-style: italic } /* Comment.PreprocFile */
.codehilite pre .c1 { color: #0099FF; font-style: italic } /* Comment.Single */
.codehilite pre .cs { color: #0099FF; font-weight: bold; font-style: italic } /* Comment.Special */
.codehilite pre .gd { background-color: #FFCCCC; border: 1px solid #CC0000 } /* Generic.Deleted */
.codehilite pre .ge { font-style: italic } /* Generic.Emph */
.codehilite pre .gr { color: #FF0000 } /* Generic.Error */
.codehilite pre .gh { color: #003300; font-weight: bold } /* Generic.Heading */
.codehilite pre .gi { background-color: #CCFFCC; border: 1px solid #00CC00 } /* Generic.Inserted */
.codehilite pre .go { color: #AAAAAA } /* Generic.Output */
.codehilite pre .gp { color: #000099; font-weight: bold } /* Generic.Prompt */
.codehilite pre .gs { font-weight: bold } /* Generic.Strong */
.codehilite pre .gu { color: #003300; font-weight: bold } /* Generic.Subheading */
.codehilite pre .gt { color: #99CC66 } /* Generic.Traceback */
.codehilite pre .kc { color: #006699; font-weight: bold } /* Keyword.Constant */
.codehilite pre .kd { color: #006699; font-weight: bold } /* Keyword.Declaration */
.codehilite pre .kn { color: #006699; font-weight: bold } /* Keyword.Namespace */
.codehilite pre .kp { color: #006699 } /* Keyword.Pseudo */
.codehilite pre .kr { color: #006699; font-weight: bold } /* Keyword.Reserved */
.codehilite pre .kt { color: #007788; font-weight: bold } /* Keyword.Type */
.codehilite pre .m { color: #FF6600 } /* Literal.Number */
.codehilite pre .s { color: #CC3300 } /* Literal.String */
.codehilite pre .na { color: #330099 } /* Name.Attribute */
.codehilite pre .nb { color: #336666 } /* Name.Builtin */
.codehilite pre .nc { color: #00AA88; font-weight: bold } /* Name.Class */
.codehilite pre .no { color: #336600 } /* Name.Constant */
.codehilite pre .nd { color: #9999FF } /* Name.Decorator */
.codehilite pre .ni { color: #999999; font-weight: bold } /* Name.Entity */
.codehilite pre .ne { color: #CC0000; font-weight: bold } /* Name.Exception */
.codehilite pre .nf { color: #CC00FF } /* Name.Function */
.codehilite pre .nl { color: #9999FF } /* Name.Label */
.codehilite pre .nn { color: #00CCFF; font-weight: bold } /* Name.Namespace */
.codehilite pre .nt { color: #330099; font-weight: bold } /* Name.Tag */
.codehilite pre .nv { color: #003333 } /* Name.Variable */
.codehilite pre .ow { color: #000000; font-weight: bold } /* Operator.Word */
.codehilite pre .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite pre .mb { color: #FF6600 } /* Literal.Number.Bin */
.codehilite pre .mf { color: #FF6600 } /* Literal.Number.Float */
.codehilite pre .mh { color: #FF6600 } /* Literal.Number.Hex */
.codehilite pre .mi { color: #FF6600 } /* Literal.Number.Integer */
.codehilite pre .mo { color: #FF6600 } /* Literal.Number.Oct */
.codehilite pre .sa { color: #CC3300 } /* Literal.String.Affix */
.codehilite pre .sb { color: #CC3300 } /* Literal.String.Backtick */
.codehilite pre .sc { color: #CC3300 } /* Literal.String.Char */
.codehilite pre .dl { color: #CC3300 } /* Literal.String.Delimiter */
.codehilite pre .sd { color: #CC3300; font-style: italic } /* Literal.String.Doc */
.codehilite pre .s2 { color: #CC3300 } /* Literal.String.Double */
.codehilite pre .se { color: #CC3300; font-weight: bold } /* Literal.String.Escape */
.codehilite pre .sh { color: #CC3300 } /* Literal.String.Heredoc */
.codehilite pre .si { color: #AA0000 } /* Literal.String.Interpol */
.codehilite pre .sx { color: #CC3300 } /* Literal.String.Other */
.codehilite pre .sr { color: #33AAAA } /* Literal.String.Regex */
.codehilite pre .s1 { color: #CC3300 } /* Literal.String.Single */
.codehilite pre .ss { color: #FFCC33 } /* Literal.String.Symbol */
.codehilite pre .bp { color: #336666 } /* Name.Builtin.Pseudo */
.codehilite pre .fm { color: #CC00FF } /* Name.Function.Magic */
.codehilite pre .vc { color: #003333 } /* Name.Variable.Class */
.codehilite pre .vg { color: #003333 } /* Name.Variable.Global */
.codehilite pre .vi { color: #003333 } /* Name.Variable.Instance */
.codehilite pre .vm { color: #003333 } /* Name.Variable.Magic */
.codehilite pre .il { color: #FF6600 } /* Literal.Number.Integer.Long */</style><script type="text/javascript" src="http://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
MathJax.Hub.Config({
  config: ["MMLorHTML.js"],
  extensions: ["tex2jax.js"],
  jax: ["input/TeX"],
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: false
  },
  TeX: {
    extensions: ["AMSmath.js", "AMSsymbols.js"],
    TagSide: "right",
    TagIndent: ".8em",
    MultLineWidth: "85%",
    equationNumbers: {
      autoNumber: "AMS",
    },
    unicode: {
      fonts: "STIXGeneral,'Arial Unicode MS'"
    }
  },
  showProcessingMessages: false
});
</script>
<title>GenSim</title>
    <meta name="robots" content="all" />
    <!-- TODO: 移动设备配置 -->
    <!-- Add to homescreen for Chrome on Android -->
    <meta name="mobile-web-app-capable" content="yes">
    <link rel="icon" sizes="192x192" href="../../images/snow.jpg">
    <!-- Add to homescreen for Safari on iOS -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="JinJay">
    <link rel="apple-touch-icon-precomposed" href="../../images/snow.jpg">
    <!-- Tile icon for Win8 (144x144 + tile color) -->
    <meta name="msapplication-TileImage" content="../../images/snow.jpg">
    <meta name="msapplication-TileColor" content="#3372DF">
    <!-- save to local storage -->
    <link href="../../mdl/icon.css" rel="stylesheet">
    <link href="http://cdn.bootcss.com/material-design-icons/3.0.1/iconfont/material-icons.min.css" rel="stylesheet">
    <!-- random generate color -->
    <link rel="stylesheet" href="../../mdl/material.deep_purple-blue.min.css" />
    <!-- template.css -->
    <link rel="stylesheet" type="text/css" href="../../stylesheets/t.css">
    <script src="../../mdl/material.min.js"></script>
  </head>
  <body>
    <!-- Uses a header that contracts as the page scrolls down. -->
    <style>
    .waterfall-demo-header-nav .mdl-navigation__link:last-of-type {
    padding-right: 0;
    }
    }
    </style>
    <div class="mdl-layout mdl-layout--fixed-header mdl-js-layout mdl-layout--overlay-drawer-button">
      <header class="mdl-layout__header mdl-layout__header--waterfall">
        <!-- Top row, always visible -->
        <div class="mdl-layout__header-row">
          <!-- TOC -->
          <span class="mdl-layout-title">目录</span>
          <div class="mdl-layout-spacer"></div>
          <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable
            mdl-textfield--floating-label mdl-textfield--align-right">
            <label class="mdl-button mdl-js-button mdl-button--icon" for="waterfall-exp">
              <i class="material-icons">search</i>
            </label>
            <div class="mdl-textfield__expandable-holder">
              <input class="mdl-textfield__input" type="text" name="sample" id="waterfall-exp" placeholder="暂不可用" />
            </div>
          </div>
        </div>
        <!-- Bottom row, not visible on scroll -->
        <div class="mdl-layout__header-row">
          <span class="mdl-layout-tile mdl-layout--large-screen-only">朝着梦想，一步一步！</span>
          <div class="mdl-layout-spacer"></div>
          <!-- Navigation -->
          <nav class="waterfall-demo-header-nav mdl-navigation">
            <a class="mdl-navigation__link" href="http://ijinjay.github.io">主页</a>
            <a class="mdl-navigation__link" href="http://ijinjay.github.io/blog/">博客</a>
            <a class="mdl-navigation__link" href="http://ijinjay.github.io/about.html">关于我</a>
          </nav>
        </div>
      </header>
      <div class="mdl-layout__drawer">
        <span class="mdl-layout-title">目录</span>
        <nav class="mdl-navigation">
          <div class="toc">
<ul>
<li><a href="#gensim">Gensim文档</a><ul>
<li><a href="#_1">语料库和向量空间</a><ul>
<li><a href="#_2">将字符串转为向量</a></li>
<li><a href="#_3">语料库流，一次处理一个文档</a></li>
<li><a href="#_4">语料库格式</a></li>
<li><a href="#numpyscipy">与NumPy和SciPy兼容</a></li>
</ul>
</li>
<li><a href="#_5">主题与转换</a><ul>
<li><a href="#_6">转换接口</a></li>
<li><a href="#_7">创建一个变换</a></li>
<li><a href="#_8">转换向量</a></li>
<li><a href="#_9">可使用的变换</a></li>
</ul>
</li>
<li><a href="#_10">相似度查询</a><ul>
<li><a href="#_11">初始化查询结构</a></li>
<li><a href="#_12">执行查询</a></li>
<li><a href="#_13">接下来是什么</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
        </nav>
      </div>
      <!-- main outer -->
      <main class="demo-main mdl-layout__content">
      <!-- grid start -->
      <div class="demo-container mdl-grid">
        <!-- placeholder cell -->
        <div class="mdl-cell mdl-cell--2-col mdl-cell--hide-tablet mdl-cell--hide-phone"></div>
        <div class="demo-content mdl-color--white mdl-shadow--4dp content mdl-color-text--grey-800 mdl-cell mdl-cell--8-col">
          <h1 id="gensim"><a name="user-content-gensim" href="#gensim" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>Gensim文档</h1>
<p>Gensim是一个免费的用来自动提取文档主题的Python库。特点：</p>
<ul>
<li>内存独立，没有必要一次把所有的训练语料库载入内容。</li>
<li>对几个流行的向量空间算法进行了高效的实现，包括<strong>Tf-Idf</strong>, <strong>Latent Semantic Analysis</strong>, <strong>Latent Dirichlet Allocation</strong>, <strong>Random Projection</strong>;添加一个新的也非常容易。</li>
<li>对几个流行的数据格式进行了IO包装和转换。</li>
<li>实现了文档相似度查询</li>
</ul>
<p>安装：<br />
<div class="codehilite"><pre><span></span>pip install gensim
</pre></div>
</p>
<h2 id="_1"><a name="user-content-_1" href="#_1" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>语料库和向量空间</h2>
<p>使用以下代码来记录日志：</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(asctime)s</span><span class="s1"> : </span><span class="si">%(levelname)s</span><span class="s1"> : </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
</pre></div>


<h3 id="_2"><a name="user-content-_2" href="#_2" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>将字符串转为向量</h3>
<p>示例：<br />
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">corpora</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">similarities</span>

<span class="n">documents</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Human machine interface for lab abc computer applications&quot;</span><span class="p">,</span>
             <span class="s2">&quot;A survey of user opinion of computer system response time&quot;</span><span class="p">,</span>
             <span class="s2">&quot;The EPS user interface management system&quot;</span><span class="p">,</span>
             <span class="s2">&quot;System and human system engineering testing of EPS&quot;</span><span class="p">,</span>
             <span class="s2">&quot;Relation of user perceived response time to error measurement&quot;</span><span class="p">,</span>
             <span class="s2">&quot;The generation of random binary unordered trees&quot;</span><span class="p">,</span>
             <span class="s2">&quot;The intersection graph of paths in trees&quot;</span><span class="p">,</span>
             <span class="s2">&quot;Graph minors IV Widths of trees and well quasi ordering&quot;</span><span class="p">,</span>
             <span class="s2">&quot;Graph minors A survey&quot;</span><span class="p">]</span>
</pre></div>
</p>
<p>需要先将每一行文档进行预处理，得到token字符，去掉不必要的字符</p>
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="c1"># 去除字符中得空格等</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">stoplist</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="s1">&#39;for a of the and to in&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">texts</span> <span class="o">=</span> <span class="p">[[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">document</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stoplist</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span>          <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># 将只出现一次的单词移除</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">frequency</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
<span class="o">&gt;&gt;&gt;</span>         <span class="n">frequency</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">texts</span> <span class="o">=</span> <span class="p">[[</span><span class="n">token</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">if</span> <span class="n">frequency</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span>          <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>   <span class="c1"># 更好的输出格式</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pprint</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
<span class="p">[[</span><span class="s1">&#39;human&#39;</span><span class="p">,</span> <span class="s1">&#39;interface&#39;</span><span class="p">,</span> <span class="s1">&#39;computer&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;survey&#39;</span><span class="p">,</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;computer&#39;</span><span class="p">,</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;response&#39;</span><span class="p">,</span> <span class="s1">&#39;time&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;eps&#39;</span><span class="p">,</span> <span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;interface&#39;</span><span class="p">,</span> <span class="s1">&#39;system&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;human&#39;</span><span class="p">,</span> <span class="s1">&#39;system&#39;</span><span class="p">,</span> <span class="s1">&#39;eps&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;user&#39;</span><span class="p">,</span> <span class="s1">&#39;response&#39;</span><span class="p">,</span> <span class="s1">&#39;time&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;trees&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;graph&#39;</span><span class="p">,</span> <span class="s1">&#39;trees&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;graph&#39;</span><span class="p">,</span> <span class="s1">&#39;minors&#39;</span><span class="p">,</span> <span class="s1">&#39;trees&#39;</span><span class="p">],</span>
 <span class="p">[</span><span class="s1">&#39;graph&#39;</span><span class="p">,</span> <span class="s1">&#39;minors&#39;</span><span class="p">,</span> <span class="s1">&#39;survey&#39;</span><span class="p">]]</span>
</pre></div>


<p>当然，处理文档的方式有很多种；这里只是简单的将空格移除，然后将每一个单词小写。处理文档的方式太多也太有针对性，所以在这一方面并没有限制。一个文档代表的是从它里面可以提取出特征，怎样获得特征由你决定。下面介绍一种通用的方法，词袋(bag-of-words)，但是需要记住，不同的应用需要不同的特征，而且，garbage in, garbage out(输入了垃圾数据，便会输出垃圾结果)。。。</p>
<p>为了将文档转化为向量，我们需要使用一个文档表示方法——词袋(bag-of-words)。每一个文档通过一个向量来表示，每一个向量都表示一个QA(question-answer)对，如下</p>
<blockquote>
<p>&ldquo;How many times does the word system appear in the document? Once.&rdquo;</p>
</blockquote>
<p>使用整型id来表示问题是十分有利的。问题和id之间的映射成为一个词典(dictionary):<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.dict&#39;</span><span class="p">)</span> <span class="c1"># 保存以备之后使用</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">dictionary</span><span class="p">)</span>
<span class="n">Dictionary</span><span class="p">(</span><span class="mi">12</span> <span class="n">unique</span> <span class="n">tokens</span><span class="p">)</span>
</pre></div>
</p>
<p>这里我们给在语料库中的每一个单词分配了一个整型id，通过<code>gensim.corpora.dictionary.Dictionary</code>类。这一步会对文本进行清理，对文本计数，并作一些相关的统计。最后，我们能够发现在处理后的语料库中有12个的单独的单词，表示每一个文档能够通过这12个数字来表示(也即12维向量)。为了可视化单词和他们的id之间的映射，可以通过print来查看。</p>
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">dictionary</span><span class="o">.</span><span class="n">token2id</span><span class="p">)</span>
<span class="p">{</span><span class="s1">&#39;minors&#39;</span><span class="p">:</span> <span class="mi">11</span><span class="p">,</span> <span class="s1">&#39;graph&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;system&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;trees&#39;</span><span class="p">:</span> <span class="mi">9</span><span class="p">,</span> <span class="s1">&#39;eps&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;computer&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="s1">&#39;survey&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;user&#39;</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span> <span class="s1">&#39;human&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;time&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;interface&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;response&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
</pre></div>


<p>实际中我们可以这样将文档转为向量：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">new_doc</span> <span class="o">=</span> <span class="s2">&quot;Human computer interaction&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">new_vec</span> <span class="o">=</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">new_doc</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">new_vec</span><span class="p">)</span> <span class="c1"># 单词&quot;interaction&quot;并没有在词袋中，我们将它舍弃</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
</pre></div>
</p>
<p>此处函数<code>doc2bow()</code>简单的计算每一个单词出现的数量，将单词与整型id结合返回一个向量。向量<code>[(0,1),(1,1)]</code>表示，在文档<code>Human computer interaction</code>中，单词<code>computer</code>(id为0)和<code>human</code>(id为1)只出现了一次；其他的单词出现0次。</p>
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.mm&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span> <span class="c1"># store to disk, for later use</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
</pre></div>


<h3 id="_3"><a name="user-content-_3" href="#_3" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>语料库流，一次处理一个文档</h3>
<p>上面的例子中，语料库完全保存在内存中，作为一个python的list对象。在这个简单的例子中，这并不重要，但是为了使事情更清晰，我们假设有语料库中有上百万个文档。内容不能完全存储这么多的内容。所以，假设文档保存在磁盘中，一个文档一行。Gensim允许每一次只处理一个文档，并返回一个文档向量。</p>
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="k">class</span> <span class="nc">MyCorpus</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="o">&gt;&gt;&gt;</span>     <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="o">&gt;&gt;&gt;</span>         <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;mycorpus.txt&#39;</span><span class="p">):</span>
<span class="o">&gt;&gt;&gt;</span>             <span class="c1"># 假设一行一个文档，文档通过空格来分别单词</span>
<span class="o">&gt;&gt;&gt;</span>             <span class="k">yield</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
</pre></div>


<p>可以尝试自己更改<code>__iter__</code>方法，来解析文档，生成单词列表，然后转化为词典。</p>
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">corpus_memory_friendly</span> <span class="o">=</span> <span class="n">MyCorpus</span><span class="p">()</span> <span class="c1"># doesn&#39;t load the corpus into memory!</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">corpus_memory_friendly</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">__main__</span><span class="o">.</span><span class="n">MyCorpus</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x10d5690</span><span class="o">&gt;</span>
</pre></div>


<p>现在语料库是一个对象。我们还没有定义任何的方法来输出它，所以print只会显示对象在内存中的地址。并不十分有用。为了看到组成向量。我们可以在语料库上进行迭代并打印文档向量。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">vector</span> <span class="ow">in</span> <span class="n">corpus_memory_friendly</span><span class="p">:</span> <span class="c1"># load one vector into memory at a time</span>
<span class="o">...</span>     <span class="k">print</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
</pre></div>
</p>
<p>尽管输出类似于纯的python列表，但是现在语料库是内存友好的，因为每一次最多有一个向量在内容中。现在语料库可以尽可能的大了。</p>
<p>同样，也可以不加载所有文本到内存来构造词典：</p>
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="c1"># 获取token的统计信息</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;mycorpus.txt&#39;</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># 去掉停止字符和那些只出现一次的单词</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">stop_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">dictionary</span><span class="o">.</span><span class="n">token2id</span><span class="p">[</span><span class="n">stopword</span><span class="p">]</span> <span class="k">for</span> <span class="n">stopword</span> <span class="ow">in</span> <span class="n">stoplist</span>
<span class="o">&gt;&gt;&gt;</span>             <span class="k">if</span> <span class="n">stopword</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">token2id</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">once_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenid</span> <span class="k">for</span> <span class="n">tokenid</span><span class="p">,</span> <span class="n">docfreq</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">dfs</span><span class="o">.</span><span class="n">iteritems</span><span class="p">()</span> <span class="k">if</span> <span class="n">docfreq</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">filter_tokens</span><span class="p">(</span><span class="n">stop_ids</span> <span class="o">+</span> <span class="n">once_ids</span><span class="p">)</span> <span class="c1"># 移除停止词和出现一次的词</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">compactify</span><span class="p">()</span> <span class="c1"># 在移除无用的词后消除id序列的间隔</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">dictionary</span><span class="p">)</span>
<span class="n">Dictionary</span><span class="p">(</span><span class="mi">12</span> <span class="n">unique</span> <span class="n">tokens</span><span class="p">)</span>
</pre></div>


<p>接下来，我们还需要面对这个问题：这些不同的单词中如何计算出有用的频率信息？我们需要在这个词典的表示上应用一些变换，在我们能够使用它来计算有意义的文档相似性之前。后面我们会讲解变换，下面我们来看看语料库持久化。</p>
<h3 id="_4"><a name="user-content-_4" href="#_4" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>语料库格式</h3>
<p>由多种文件格式可以选择来序列化一个向量空间的语料库到本地磁盘。Gensim通过流语料库接口来实现：文档采用懒惰读取，一次一个文档，不用一次读取全部内容。</p>
<p>其中一种文件格式是<a href="http://math.nist.gov/MatrixMarket/formats.html">Market Matrix fomat</a>。采用这个来保存语料库如下：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">corpora</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># 创建一个有两个文档的示例语料库</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">corpus</span> <span class="o">=</span> <span class="p">[[(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)],</span> <span class="p">[]]</span>  <span class="c1"># 是其中一个文档为空，来看看它的魔力</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="s1">&#39;/tmp/corpus.mm&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
</pre></div>
</p>
<p>其他的格式包括<a href="http://svmlight.joachims.org/">Joachim&rsquo;s SVMlight format</a>, <a href="http://www.cs.princeton.edu/~blei/lda-c/">Blei&rsquo;s LDA-C format</a>,<a href="http://gibbslda.sourceforge.net/">GibblesLDA++ format</a>。</p>
<p><div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">corpora</span><span class="o">.</span><span class="n">SvmLightCorpus</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="s1">&#39;/tmp/corpus.svmlight&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">corpora</span><span class="o">.</span><span class="n">BleiCorpus</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="s1">&#39;/tmp/corpus.lda-c&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">corpora</span><span class="o">.</span><span class="n">LowCorpus</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="s1">&#39;/tmp/corpus.low&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
</pre></div>
<br />
相对地，从一个matrix market 文件中加载语料库迭代器：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">corpus</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="p">(</span><span class="s1">&#39;/tmp/corpus.mm&#39;</span><span class="p">)</span>
</pre></div>
</p>
<p>Corpus对象是一种流，所以不可以直接打印输出信息：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">MmCorpus</span><span class="p">(</span><span class="mi">2</span> <span class="n">documents</span><span class="p">,</span> <span class="mi">2</span> <span class="n">features</span><span class="p">,</span> <span class="mi">1</span> <span class="n">non</span><span class="o">-</span><span class="n">zero</span> <span class="n">entries</span><span class="p">)</span>
</pre></div>
</p>
<p>查看信息：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="c1"># 一个输出corpus的方法:将它全部加载进内存</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">corpus</span><span class="p">))</span> <span class="c1"># 调用list()方法会是所有的序列变为纯的python列表</span>
<span class="p">[[(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)],</span> <span class="p">[]]</span>
</pre></div>
<br />
或者：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="c1"># another way of doing it: print one document at a time, making use of the streaming interface</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
<span class="o">...</span>     <span class="k">print</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
<span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)]</span>
<span class="p">[]</span>
</pre></div>
</p>
<p>很显然第二种方法更加内存友好。</p>
<p>可以使用如下代码使用Blei&rsquo;s LDA-C格式来保存相同的Matrix Market文档流。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">corpora</span><span class="o">.</span><span class="n">BleiCorpus</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="s1">&#39;/tmp/corpus.lda-c&#39;</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>
</pre></div>
</p>
<p>这样，gensim也能够用来作为一个高效内存的IO格式转化工具：使用一种格式加载文档流然后直接使用另外一种格式保存。</p>
<h3 id="numpyscipy"><a name="user-content-numpyscipy" href="#numpyscipy" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>与NumPy和SciPy兼容</h3>
<p>Gensim包含了一些高效的工具函数来帮助与numpy数据格式进行相互转换。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">corpus</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">matutils</span><span class="o">.</span><span class="n">Dense2Corpus</span><span class="p">(</span><span class="n">numpy_matrix</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">numpy_matrix</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">matutils</span><span class="o">.</span><span class="n">corpus2dense</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">num_terms</span><span class="o">=</span><span class="n">number_of_corpus_features</span><span class="p">)</span>
</pre></div>
</p>
<p>也能够与scipy进行相互转换。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">corpus</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">matutils</span><span class="o">.</span><span class="n">Sparse2Corpus</span><span class="p">(</span><span class="n">scipy_sparse_matrix</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">scipy_csc_matrix</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">matutils</span><span class="o">.</span><span class="n">corpus2csc</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</pre></div>
</p>
<h2 id="_5"><a name="user-content-_5" href="#_5" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>主题与转换</h2>
<h3 id="_6"><a name="user-content-_6" href="#_6" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>转换接口</h3>
<p>继续上一节的内容，先加载语料库：</p>
<p><div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">corpora</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">similarities</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.dict&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">corpus</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.mm&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">MmCorpus</span><span class="p">(</span><span class="mi">9</span> <span class="n">documents</span><span class="p">,</span> <span class="mi">12</span> <span class="n">features</span><span class="p">,</span> <span class="mi">28</span> <span class="n">non</span><span class="o">-</span><span class="n">zero</span> <span class="n">entries</span><span class="p">)</span>
</pre></div>
<br />
下面演示如何将文档从一个向量空间转换到另一个。这个过程有两个目标：<br />
1. 显现我们语料库的隐藏结构，找到词与词之间的关系，并使用他们以更加语义化的方式来描述新的文档。<br />
2. 使文档表示更加坚实。包括提升效率(新表示方法需要更少的资源)和功效(去除无效的数据，降噪)。</p>
<h3 id="_7"><a name="user-content-_7" href="#_7" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>创建一个变换</h3>
<p>变换是一个标准的Python对象，通常从一个训练的语料库中初始化。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">tfidf</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">TfidfModel</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="c1"># 步骤1，初始化一个模型</span>
</pre></div>
<br />
使用我们之前的语料库来初始化一个变换模型。不同的变换可能需要不同的初始化参数；就<code>Tfidf</code>方法而言，训练的组成包扩遍历一遍提供的语料库和计算文档的所有特征的频率。训练其他的模型，比如<code>Latent Semantic Analysis</code>或者<code>Latent Dirichlet Allocation</code>，需要更深入的同时更多次的遍历。</p>
<blockquote>
<p>注：变换总是在两个特定的向量空间之间进行。必须使用相同的向量空间(也就是特征id相同)来训练和进行子向量变换。使用相同的输入特征空间会导致错误，比如应用一个不同的字符创处理函数，使用不同的特征id，或者在应该使用Tfidf向量的时候使用了词袋向量，这些都会使得变换过程中特征不匹配，最终导致garbage out或者运行时异常。</p>
</blockquote>
<h3 id="_8"><a name="user-content-_8" href="#_8" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>转换向量</h3>
<p>到此，<code>tfidf</code>被作为一个只读的对象，能够将任意的一个向量从旧的表示方法(词袋)转换为一个新的表示(Tfidf真值权重)。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">doc_bow</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">tfidf</span><span class="p">[</span><span class="n">doc_bow</span><span class="p">])</span> <span class="c1"># 步骤2，使用模型来转换向量</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.70710678</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.70710678</span><span class="p">)]</span>
</pre></div>
<br />
后者，在整个语料库上进行转换：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">corpus_tfidf</span> <span class="o">=</span> <span class="n">tfidf</span><span class="p">[</span><span class="n">corpus</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus_tfidf</span><span class="p">:</span>
<span class="o">...</span>     <span class="k">print</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.57735026918962573</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.57735026918962573</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.57735026918962573</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.44424552527467476</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">0.44424552527467476</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mf">0.44424552527467476</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.32448702061385548</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mf">0.44424552527467476</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mf">0.32448702061385548</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5710059809418182</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.41707573620227772</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mf">0.41707573620227772</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mf">0.5710059809418182</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.49182558987264147</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.71848116070837686</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mf">0.49182558987264147</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">0.62825804686700459</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mf">0.62825804686700459</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mf">0.45889394536615247</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">9</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">9</span><span class="p">,</span> <span class="mf">0.70710678118654746</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.70710678118654746</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">9</span><span class="p">,</span> <span class="mf">0.50804290089167492</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.50804290089167492</span><span class="p">),</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mf">0.69554641952003704</span><span class="p">)]</span>
<span class="p">[(</span><span class="mi">4</span><span class="p">,</span> <span class="mf">0.62825804686700459</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.45889394536615247</span><span class="p">),</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mf">0.62825804686700459</span><span class="p">)]</span>
</pre></div>
</p>
<p>在这个特定的例子中，我们能够转化之前用于训练的相同的语料库，但是结果是次要的。一旦变换模型被初始化，它就可以用在任何向量上(当然，假定他们来自相同的向量空间),即使没有在训练的语料库中使用过。这通过LSA中被称为<code>folding-in</code>过程实现。</p>
<blockquote>
<p>注：调用<code>model[corpus]</code>只会创建一个对旧的数据流的包装，真正的变换是在文档迭代的过程中飞速完成的。我们不能在调用<code>corpus_transformed=model[corpus]</code>时转换所有的语料库，因为这意味着保存结果到内存中，与gensim的内存独立相违背。如果需要多次迭代变换<code>corpus_transformed</code>,然后转换的开销很大，可以先将其序列化到磁盘上，然后继续使用。</p>
</blockquote>
<p>转换可以序列化，在一条链上：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">lsi</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">LsiModel</span><span class="p">(</span><span class="n">corpus_tfidf</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># 初始化一个LSI变换</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">corpus_lsi</span> <span class="o">=</span> <span class="n">lsi</span><span class="p">[</span><span class="n">corpus_tfidf</span><span class="p">]</span> <span class="c1"># 在原来的语料库上创建两个包装，bow-&gt;tfidf-&gt;fold-in-lsi</span>
</pre></div>
<br />
上面我们通过<a href="http://en.wikipedia.org/wiki/Latent_semantic_indexing">Latent Semantic Indexing</a>将tf-idf语料库转换为一个二维空间(我们设定num_topics=2)。现在，有可能好奇：这两个维度代表什么？我们可以看一下它的内部：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">lsi</span><span class="o">.</span><span class="n">print_topics</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">topic</span> <span class="c1">#0(1.594): -0.703*&quot;trees&quot; + -0.538*&quot;graph&quot; + -0.402*&quot;minors&quot; + -0.187*&quot;survey&quot; + -0.061*&quot;system&quot; + -0.060*&quot;response&quot; + -0.060*&quot;time&quot; + -0.058*&quot;user&quot; + -0.049*&quot;computer&quot; + -0.035*&quot;interface&quot;</span>
<span class="n">topic</span> <span class="c1">#1(1.476): -0.460*&quot;system&quot; + -0.373*&quot;user&quot; + -0.332*&quot;eps&quot; + -0.328*&quot;interface&quot; + -0.320*&quot;response&quot; + -0.320*&quot;time&quot; + -0.293*&quot;computer&quot; + -0.280*&quot;human&quot; + -0.171*&quot;survey&quot; + 0.161*&quot;trees&quot;</span>
</pre></div>
<br />
(topic信息被打印到日志中)</p>
<p>根据LSI，&rdquo;trees&rdquo;, &ldquo;graph&rdquo;, &ldquo;minors&rdquo;是所有的相关的单词(并且在首要主题上的贡献最大)，而第二个主题与所有的其他词都相关联。正如期待的那样，前五个文档与第二个主题是足够相关的，而剩下的与第一个主题相关。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">corpus_lsi</span><span class="p">:</span> <span class="c1"># bow-&gt;tfidf和tfidf-&gt;lsi变换都会在这里快速执行</span>
<span class="o">...</span>     <span class="k">print</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.066</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.520</span><span class="p">)]</span> <span class="c1"># &quot;Human machine interface for lab abc computer applications&quot;</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.197</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.761</span><span class="p">)]</span> <span class="c1"># &quot;A survey of user opinion of computer system response time&quot;</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.090</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.724</span><span class="p">)]</span> <span class="c1"># &quot;The EPS user interface management system&quot;</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.076</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.632</span><span class="p">)]</span> <span class="c1"># &quot;System and human system engineering testing of EPS&quot;</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.102</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.574</span><span class="p">)]</span> <span class="c1"># &quot;Relation of user perceived response time to error measurement&quot;</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.703</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.161</span><span class="p">)]</span> <span class="c1"># &quot;The generation of random binary unordered trees&quot;</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.877</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.168</span><span class="p">)]</span> <span class="c1"># &quot;The intersection graph of paths in trees&quot;</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.910</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.141</span><span class="p">)]</span> <span class="c1"># &quot;Graph minors IV Widths of trees and well quasi ordering&quot;</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.617</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.054</span><span class="p">)]</span> <span class="c1"># &quot;Graph minors A survey&quot;</span>
</pre></div>
</p>
<p>模型的持久化使用save()和load()函数：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">lsi</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/tmp/model.lsi&#39;</span><span class="p">)</span> <span class="c1"># same for tfidf, lda, ...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lsi</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">LsiModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/tmp/model.lsi&#39;</span><span class="p">)</span>
</pre></div>
</p>
<p>下一个问题是：两个文档是如何相似的？是否存在一个方法来确定相似度，对于一个给定的输入文档，我们可以根据相似度来处理其它的文档？下一节我们会介绍相似度。</p>
<h3 id="_9"><a name="user-content-_9" href="#_9" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>可使用的变换</h3>
<p>Gensim包含一些流行的向量空间模型算法：</p>
<ul>
<li><a href="http://en.wikipedia.org/wiki/Tf–idf">Term Frequency * Inverse Document Frequency, Tf-Idf</a>接受词袋训练向量来初始化。在变换过程中，可以将一个向量转换为相同维度的向量，使得训练数据中的稀有特征的值得到增加。它最后将整型的向量转换为实数值，保留数字的维度不变。也可以可选地归一化结果向量为单位长度。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">tfidfmodel</span><span class="o">.</span><span class="n">TfidfModel</span><span class="p">(</span><span class="n">bow_corpus</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</li>
<li><a href="http://en.wikipedia.org/wiki/Latent_semantic_indexing">Latent Semantic Indexing, LSI (浅语义标号，有时也称LSA)</a>将文档从词袋或(更可取的)Tfidf权重空间转换为一个低维度的潜层空间。在上面的示例中我们使用了两个浅层，但是实际的语料库中，200-500的目标维度被认为是一个&rdquo;黄金标准&rdquo;。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">tfidfmodel</span><span class="o">.</span><span class="n">TfidfModel</span><span class="p">(</span><span class="n">bow_corpus</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
<br />
LSI训练是唯一的，我们可以在任何时候继续训练，只需要提供更多的训练文档。这通过递增更新隐含模型来完成，这个过程被称为&rdquo;在线训练&rdquo;。因为这个特性，输入文档流甚至可以使无限的，只需要保持提供LSI新的文档，同时只读地使用这个计算转换的模型。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">add_documents</span><span class="p">(</span><span class="n">another_tfidf_corpus</span><span class="p">)</span> <span class="c1"># now LSI has been trained on tfidf_corpus + another_tfidf_corpus</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lsi_vec</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="n">tfidf_vec</span><span class="p">]</span> <span class="c1"># convert some new document into the LSI space, without affecting the model</span>
<span class="o">&gt;&gt;&gt;</span> <span class="o">...</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">add_documents</span><span class="p">(</span><span class="n">more_documents</span><span class="p">)</span> <span class="c1"># tfidf_corpus + another_tfidf_corpus + more_documents</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lsi_vec</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="n">tfidf_vec</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="o">...</span>
</pre></div>
<br />
查看<code>gensim.models.lsimodel</code>文档来获取使得LSI在无穷的输入流中渐进忘记旧的观测值的细节。如果想更进一步，也有一些参数你可以用来调节以改变LSI算法的速度或内存空间或数字精度。</li>
<li><a href="http://www.cis.hut.fi/ella/publications/randproj_kdd.pdf">Random Projections, RP(随机映射)</a>主要目的是减少向量空间的维度。这是一个非常高效的(CPU和内存)方法，通过扔一些随机数来近似文档间的Tfidf距离。推荐的目标维度基于数据集在成百上千之间。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">rpmodel</span><span class="o">.</span><span class="n">RpModel</span><span class="p">(</span><span class="n">tfidf_corpus</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</li>
<li>
<p><a href="http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">Latent Dirichlet Allocation, LDA</a>是另一种将词袋计数向量转换为低纬度主题空间的方法。LDA是LSA(也称多项分布PCA)的概率扩展，所以LDA的主题能够被解释为单词上的概率分布。这些分布，像LSA那样，通过训练语料库来自动推断。文档返过来解释这些主题的混合情况。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">ldamodel</span><span class="o">.</span><span class="n">LdaModel</span><span class="p">(</span><span class="n">bow_corpus</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
<br />
gensim使用一个在线LDA参数评价的快速实现，可以在分布式集群上运行。</p>
</li>
<li>
<p><a href="http://jmlr.csail.mit.edu/proceedings/papers/v15/wang11a/wang11a.pdf">Hierarchical Dirichlet Process, HDP</a>是一个非参数的贝叶斯方法(表示请求主题的缺省数目)：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">model</span> <span class="o">=</span> <span class="n">hdpmodel</span><span class="o">.</span><span class="n">HdpModel</span><span class="p">(</span><span class="n">bow_corpus</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">dictionary</span><span class="p">)</span>
</pre></div>
<br />
gensim使用一个快速的在线实现。HDP模型是新添加如gensim的，在一些边界上存在问题，需要注意。</p>
</li>
</ul>
<p>增加新的VSM变换(比如不同权重模式)十分简单，查看<a href="http://radimrehurek.com/gensim/apiref.html">API文档</a>获得更多的细节。</p>
<p>值得再提一下的是，存在递增的不需要一次加载所有训练语料库的实现。注意内存的使用，是十分重要的。</p>
<h2 id="_10"><a name="user-content-_10" href="#_10" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>相似度查询</h2>
<p>相似度查询指文档间的相似度，或者一个特定文档与一系列其它文档的集合的相似度。</p>
<p>为了演示在gensim中如何完成，我们考虑之前的示例。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">corpora</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">similarities</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.dict&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">corpus</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">MmCorpus</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.mm&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">MmCorpus</span><span class="p">(</span><span class="mi">9</span> <span class="n">documents</span><span class="p">,</span> <span class="mi">12</span> <span class="n">features</span><span class="p">,</span> <span class="mi">28</span> <span class="n">non</span><span class="o">-</span><span class="n">zero</span> <span class="n">entries</span><span class="p">)</span>
</pre></div>
<br />
接下来定义一个二维的LSI空间。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">lsi</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">LsiModel</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</p>
<p>现在假定一个用户输入了查询词<code>Human computer interaciton</code>。我们应该能够讲九个语料库文档根据相关性进行排序。与现代搜索引擎不同，这里我们把重心放在单个概率相似性上——也即单词文本的明显的寓意相关性。不考虑超链接、随机游走、只考虑语义扩展。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">doc</span> <span class="o">=</span> <span class="s2">&quot;Human computer interaction&quot;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">vec_bow</span> <span class="o">=</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">vec_lsi</span> <span class="o">=</span> <span class="n">lsi</span><span class="p">[</span><span class="n">vec_bow</span><span class="p">]</span> <span class="c1"># convert the query to LSI space</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">vec_lsi</span><span class="p">)</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.461821</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.070028</span><span class="p">)]</span>
</pre></div>
</p>
<p>另外，我们会考虑<a href="http://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a>来决定两个向量的相似度。</p>
<h3 id="_11"><a name="user-content-_11" href="#_11" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>初始化查询结构</h3>
<p>比较之前，我们需要输入所有用来比较的文档。这里有九个文档，用来训练LSI，转换为二维的LSD空间。不过，这个是可以渐进增加的，我们可以一起索引其它的语料库。<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">index</span> <span class="o">=</span> <span class="n">similarities</span><span class="o">.</span><span class="n">MatrixSimilarity</span><span class="p">(</span><span class="n">lsi</span><span class="p">[</span><span class="n">corpus</span><span class="p">])</span> <span class="c1"># 转换语料库到LSI空间并索引它</span>
</pre></div>
</p>
<blockquote>
<p>警告：类<code>similarities.MatrixSimilarity</code>只适合于所有的向量都在内存中。内存过少可以使用<code>similarities.Similarity</code>类。这个类使用固定的内存来操作，通过分片来实现。在内部它使用<code>similarities.MatrixSimilarity</code>和<code>similarities.SparseMatrixSimilarity</code>两个类，所以很快，尽管看起来更复杂些。</p>
</blockquote>
<p>索引持久化通过标准的<code>save()</code>和<code>load()</code>函数来实现：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">index</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.index&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">index</span> <span class="o">=</span> <span class="n">similarities</span><span class="o">.</span><span class="n">MatrixSimilarity</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;/tmp/deerwester.index&#39;</span><span class="p">)</span>
</pre></div>
</p>
<h3 id="_12"><a name="user-content-_12" href="#_12" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>执行查询</h3>
<p>获得查询文档的相似度:<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">sims</span> <span class="o">=</span> <span class="n">index</span><span class="p">[</span><span class="n">vec_lsi</span><span class="p">]</span> <span class="c1"># perform a similarity query against the corpus</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">sims</span><span class="p">)))</span> <span class="c1"># print (document_number, document_similarity) 2-tuples</span>
<span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.99809301</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.93748635</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.99844527</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">0.9865886</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mf">0.90755945</span><span class="p">),</span>
<span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.12416792</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1063926</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.098794639</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mf">0.05004178</span><span class="p">)]</span>
</pre></div>
</p>
<p>Cosine测量返回(-1,1)之间的相似度。</p>
<p>使用Python的标准函数，我们可以对相似度进行排序：<br />
<div class="codehilite"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">sims</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">sims</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">item</span><span class="p">:</span> <span class="o">-</span><span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="k">print</span><span class="p">(</span><span class="n">sims</span><span class="p">)</span>   <span class="c1"># print sorted (document number, similarity score) 2-tuples</span>
<span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.99844527</span><span class="p">),</span> <span class="c1"># The EPS user interface management system</span>
<span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.99809301</span><span class="p">),</span>  <span class="c1"># Human machine interface for lab abc computer applications</span>
<span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">0.9865886</span><span class="p">),</span>   <span class="c1"># System and human system engineering testing of EPS</span>
<span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.93748635</span><span class="p">),</span>  <span class="c1"># A survey of user opinion of computer system response time</span>
<span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mf">0.90755945</span><span class="p">),</span>  <span class="c1"># Relation of user perceived response time to error measurement</span>
<span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mf">0.050041795</span><span class="p">),</span> <span class="c1"># Graph minors A survey</span>
<span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.098794639</span><span class="p">),</span><span class="c1"># Graph minors IV Widths of trees and well quasi ordering</span>
<span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1063926</span><span class="p">),</span>  <span class="c1"># The intersection graph of paths in trees</span>
<span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.12416792</span><span class="p">)]</span> <span class="c1"># The generation of random binary unordered trees</span>
</pre></div>
</p>
<p>需要注意的是文档2和4不可能会在标准布尔全文搜索中出现，因为它们与查询词没有任何共同词。然而，在应用了LSI后，我们能够查看到这两个都返回了较高的相似度，与我们的查询有很高的相关性。事实上，这个语义泛化正式我们首先应用变换和做主题建模的原因。</p>
<h3 id="_13"><a name="user-content-_13" href="#_13" class="headeranchor-link" aria-hidden="true"><span class="headeranchor"></span></a>接下来是什么</h3>
<p>祝贺，已经完成了辅导入门内容。后面可以查看API及Wikipedia实验或者查看gensim中的分布式计算内容。</p>
<p>Gensim是一个相当成熟的包，被很多人和公司使用，在生产环境下可以进行原型开发。但并不意味着它是足够完美的：</p>
<ul>
<li>存在一些需要更高效实现的地方(比如用C实现)，或者并行的实现。</li>
<li>新的算法层出不穷。</li>
</ul>
  <p style="text-align: right; color: gray;"><br>2018-08-16 15:39:24</p>
        </div>
      </div>
      <footer>
        <p>
          JinJay's blog<a href="https://github.com/ijinjay" target="_blank">@JinJay</a>.
        </p>
        <script src="http://s4.cnzz.com/z_stat.php?id=1253269299&amp;web_id=1253269299" language="JavaScript"></script>
      </footer>
      </main>
    </div>
  </body>
</html>

